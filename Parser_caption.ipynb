{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sentiment analysis with textblob at the movie's caption. use time interval 1 sec, find positive, negative, neutral sentiments for each video. Have a dictionary with: the title of caption, the intervals  , the sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysrt\n",
    "from datetime import date, datetime, timedelta, time\n",
    "import pysrt\n",
    "from textblob import TextBlob\n",
    "import matplotlib\n",
    "from matplotlib import style\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (16.0, 9.0)\n",
    "style.use('fivethirtyeight')\n",
    "import os\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import os, re, sys\n",
    "from stat import *\n",
    "\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "from nltk import tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/mscuser/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.downloader.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling srt Subtitles"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Loading the Subtitle\n",
    "subs = pysrt.open('/home/mscuser/multimodal/multimodal_audio/Travis Scott Shows Off His Broadway Musical Abilities-QV9nArq7phA.en.srt')\n",
    "subtitles={}\n",
    "len_subs=len(subs)\n",
    "for i in range(len_subs):\n",
    "    sub = subs[i]\n",
    "\n",
    "    # Subtitle text\n",
    "    text = sub.text\n",
    "    text_without_tags = sub.text_without_tags\n",
    "\n",
    "    # Start and End time\n",
    "    start = sub.start.to_time()\n",
    "    end = sub.end.to_time()\n",
    "    subtitles[i]=[[text,text_without_tags,start,end]]\n",
    "    \n",
    "\n",
    "    print sub.text\n",
    "    print sub.start\n",
    "    print sub.end\n",
    "    print sub.end-sub.start\n",
    "print len(subtitles)\n",
    "print subtitles[99]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# textblob sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def textblob_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    polarity = blob.sentiment.polarity\n",
    "    return polarity\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vader sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''VADER produces four sentiment metrics from these word ratings, \n",
    "which you can see below. The first three, positive, neutral and negative, \n",
    "represent the proportion of the text that falls into those categories. \n",
    "As you can see, our example sentence was rated as 45% positive, \n",
    "55% neutral and 0% negative. The final metric, the compound score, \n",
    "is the sum of all of the lexicon ratings (1.9 and 1.8 in this case) \n",
    "which have been standardised to range between -1 and 1. \n",
    "In this case, our example sentence has a rating of 0.69, which is pretty strongly positive.'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "def vader_sentiment(text):\n",
    "    polarity=sid.polarity_scores(text)['compound']\n",
    "    return polarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_sentiment(file):\n",
    "    # Reading Subtitleget_sentiment\n",
    "    subs = pysrt.open(file, encoding='iso-8859-1')\n",
    "    n = len(subs)\n",
    "    # List to store the time periods\n",
    "    intervals = []\n",
    "    sentiments_text_blob = []\n",
    "    sentiments_vader = []\n",
    "\n",
    "    # Collect and combine all the text in each time interval\n",
    "    for i in range(n):\n",
    "        text = \"\"\n",
    "     \n",
    "        # Finding all subtitle text in the each time interval\n",
    "        segment=subs[i].end-subs[i].start\n",
    "       # print \"end:\" + str(subs[i].end)+ \"strat:\" +str(subs[i].start) + \"segment:\"+str(segment) + \"segment.to_time:\"+str(segment.to_time())\n",
    "        intervals.append(subs[i].start + segment)\n",
    "        #for example [0,4],[4,6]->4,6\n",
    "        if subs[i].end.to_time() <= (subs[i].start+ intervals[i]).to_time():\n",
    "             text += subs[i].text_without_tags + \" \"\n",
    "             \n",
    "        else:\n",
    "            break\n",
    "        # Sentiment Analysis with TextBlob\n",
    "  \n",
    "        sentiment_blob=textblob_sentiment(text)\n",
    "        sentiments_text_blob.append(sentiment_blob)\n",
    "      \n",
    "        # Sentiment Analysis with Vader\n",
    "        sentiment_vader=vader_sentiment(text)\n",
    "        sentiments_vader.append(sentiment_vader)\n",
    "        \n",
    "   # print sentiments_vader\n",
    "   # print sentiments_text_blob\n",
    "    #find the avrage of the 2 different sentiment analysis\n",
    "    avg_sentiments=[(a_i + b_i)/float(2) for a_i, b_i in zip(sentiments_vader, sentiments_text_blob)]\n",
    "  #  print avg_sentiments\n",
    "    return (intervals, sentiments_text_blob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility to find average sentiment\n",
    "def average(y):\n",
    "    avg = float(sum(y))/len(y)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dict={id, path, , intervals, sentiments}\n",
    "dict={}\n",
    "\n",
    "i=interval_segments=sentiment_segments=0\n",
    "def walktree(TopMostPath, callback):\n",
    "\n",
    "    '''recursively descend the directory tree rooted at TopMostPath,\n",
    "       calling the callback function for each regular file'''\n",
    "    global dict\n",
    "    for f in os.listdir(TopMostPath):\n",
    "        pathname = os.path.join(TopMostPath, f)\n",
    "        mode = os.stat(pathname)[ST_MODE]\n",
    "        if S_ISDIR(mode):\n",
    "            # It's a directory, recurse into it\n",
    "            walktree(pathname, callback)\n",
    "        elif S_ISREG(mode):\n",
    "            # It's a file, call the callback function\n",
    "            callback(pathname)\n",
    "        else:\n",
    "            # Unknown file type, print a message\n",
    "            print 'Skipping %s' % pathname\n",
    "\n",
    "\n",
    "def sentiment(file):\n",
    "    \n",
    "    global i \n",
    "    global interval_segments, sentiment_segments\n",
    "    #the srt files we need to train our model\n",
    "    if '.srt' in file:\n",
    "        interval_segments, sentiment_segments = get_sentiment(file)\n",
    "        #fig, ax = plt.subplots()\n",
    "        #plt.plot(interval_segments,sentiment_segments)\n",
    "        #plt.title(file, fontsize=32)\n",
    "        #plt.ylim((-1, 1))\n",
    "        #plt.ylabel(\"Sentiment Polarity\")\n",
    "        #plt.xlabel(\"Running Time\")\n",
    "        #plt.text(.5, 1.03, \"Average Sentiment - \" + str(round(average(y), 4)), color=\"green\")\n",
    "        \n",
    "        #DICTIONARY PATH,INTERVALS,SENTIMENTS\n",
    "        dict[i]={}\n",
    "        dict[i]['Id']=i\n",
    "        dict[i]['path']=file\n",
    "        dict[i]['intervals']=interval_segments\n",
    "        dict[i]['sentiments']=sentiment_segments\n",
    "        i=i+1\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/mscuser/multimodal/multimodal_audio'\n",
    "walktree(path, sentiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a csv for all videos that contains:videoid, path, list of interval segments, list of sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dict)):\n",
    "    with open('captions_polarity.csv', 'wb') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for key, value in dict.items():\n",
    "            writer.writerow([key, value])\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print len(sentiment_segments)\n",
    "#print sentiment_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print interval_segments[0]\n",
    "#print interval_segments[1]\n",
    "#print interval_segments[99]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Polarity>0-->Positive, POlarity<0-->Negative, Polarity=0-->Neutral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a csv for each video that contains: segment interval, pollarity for all  segments of the video.  The name of the file is polarity follwed by videoId. eg:polarity0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polarity0.csv\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dict)):\n",
    "    new_csv='polarity'+str(dict[i]['Id']) +'.csv'\n",
    "    with open(new_csv, 'wb') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for j in range(len(dict[i]['intervals'])):\n",
    "            context=(dict[i]['intervals'][j],dict[i]['sentiments'][j])\n",
    "            writer.writerows([context])\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "          "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#    Find the mean of positives, negatives per movie and add it at them at teh existing dictionary"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "for i in range(len(dict)):\n",
    "    #for earch movie\n",
    "    positives=[]\n",
    "    negatives=[]\n",
    "    for j in range(len(dict[i][2])):\n",
    "        if float(dict[i][2][j])>float(0):\n",
    "            positives.append(dict[i][2][j])\n",
    "        elif float(dict[i][2][j])<0:\n",
    "            negatives.append(dict[i][2][j])\n",
    "   \n",
    "    \n",
    "    dict[i]=dict[i] + (np.mean(positives),)\n",
    "    dict[i]=dict[i] + (np.mean(negatives),)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
